[{"id":0,"href":"/features/auto-ml/","title":"Auto Ml","section":"Features","content":"AutoML (Katib) #  Katib is a Kubernetes-native project for automated machine learning (AutoML). Katib supports hyperparameter tuning, early stopping and neural architecture search (NAS). Learn more about AutoML at fast.ai, Google Cloud, Microsoft Azure or Amazon SageMaker.\nComming soon #  "},{"id":1,"href":"/features/multi-tenancy/","title":"Multi Tenancy","section":"Features","content":"Multi-Tenancy #  Multi-user isolation and identity access management (IAM)\nComming soon #  "},{"id":2,"href":"/features/notebooks/","title":"Notebooks","section":"Features","content":"Kubeflow notebooks #  Kubeflow Notebooks provides a way to run web-based development environments inside your Kubernetes cluster by running them inside Pods.\nComming soon #  "},{"id":3,"href":"/features/pipelines/","title":"Pipelines","section":"Features","content":"Kubeflow Pipelines #  Kubeflow Pipelines is a platform for building and deploying portable, scalable machine learning (ML) workflows based on Docker containers.\nComming soon #  "},{"id":4,"href":"/getting-started/deploy-kubeflow-on-cloud/","title":"Deploy Kubeflow on Cloud","section":"Getting Started","content":"Kubeflow #  Kubeflow has been available via stacks of components. At present there is only one stack (for GCP), yet more will come in the near future.\nDeployment Prerequisites #   You should be signed in and have an active project in GCP: https://console.cloud.google.com You should have already deployed a GKE cluster   Note: there is a separate stack for GKE. It can act as an example, please feel free to customize the stack and deploy it: link\n Quick Start #  Choose a kubeflow template and run a cloud shell session.\nhub stack init hub stack deploy Or the following, if you want to review settings before deployment.\nhub stack init hub stack configure hub stack deploy List of pre-built Kubeflow stacks deployable via GCP Cloud Shell.\n   Kubeflow Stack Description Link     Kubeflow cluster v1.2 This is our latest Kubeflow stack available     Under the Hood #  Cloud Shell Editor #  Cloud Shell Editor is the ephemeral container that runs in your GCP project. You can access it via your Internet browser. You will also see a VSCode, as a convinient way to review configuration and modify stack and it\u0026rsquo;s components if needed. Basically you can use VSCode as your DevOps IDE.\nUse terminal for deployment: we use hub cli as a a single deployment tool that can switch between different deployment tools, native to each individual component and pass input and output parameters between them.\nEach Cloud Shell session will use a special Toolbox Image optimized to run as a Cloud Shell Editor container. It contains all necessary and pre-tested tools to execute Kubeflow deployment.\n Toolbox content can be found here: https://github.com/agilestacks/toolbox/tree/google/gcp-cloud-shell Pulled from GCR registry: gcr.io/superhub/cloud-shell  Primary tools used during the deployment:\n gcloud kubectl (with kustomze v4.0+) helm git  What happens during the deployment #  When you run a hub stack init Then hub will read a components described in hub.yaml file and download it. It will also prompt for GCP project. There are number of hub extensions (plugins) primarilly written in shell. You will find it in hub.yaml in the section called extensions\nWhen you run hub stack configure (or implicitly during hub stack deploy), then gcp extension will generate a new domain name and store it in the form of HUB_DOMAIN_NAME variable. Actually all variables has been pased to the hub.yaml via .env file. You don\u0026rsquo;t want to put your .env file in the git.\nThis domain name will be used by the hub as a natural ID of your deployment. If you have your own domain available as a DNS zone in GCP, then you can set it by running:\nhub stack configure --domain-name kubeflow.example.com TLS is a required by Kubeflow. It has been managed by cert-manager component. We use Lets Encrypt as the ACME provider.\n"},{"id":5,"href":"/technical-documentation/architecture/","title":"Architecture","section":"Technical Documentation","content":"Architecture #  Comming soon #  "},{"id":6,"href":"/technical-documentation/components/","title":"Components","section":"Technical Documentation","content":"Components #  This distribution of Kubeflow is consist from next components:\n Argo Workflows Istio Ingress Gateway Kubeflow Authn HTTP Filter Kubeflow Central Dashboard Kubeflow Jupyter Notebook Kubeflow pipelines  "},{"id":7,"href":"/technical-documentation/components/argo-workflows/","title":"Argo Workflows","section":"Components","content":"Argo Workflows #  Description #  Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. Argo Workflows is implemented as a Kubernetes CRD.\n Define workflows where each step in the workflow is a container. Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a graph (DAG). Easily run compute intensive jobs for machine learning or data processing in a fraction of the time using Argo Workflows on Kubernetes. Run CI/CD pipelines natively on Kubernetes without configuring complex software development products.  Implementation Details #  The Argo Workflows Component has the following directory structure:\n./ ├── hub-component.yaml # configuration and parameters file of Hub component ├── values.yaml.template # template of Helm\u0026#39;s values.yaml file ├── post-deploy # script that is executed after deploy of the current component ├── post-undeploy # script that is executed after undeploy of the current component ├── pre-deploy # script that is executed before deploy of the current component ├── charts/ # directory for Helm Chart sources ├── resources/ # component custom resource descriptors └── backup # shell script that contains backup routines The component uses an offical Helm Chart to provision Argo Forkflows.\nTo make configuration more flexible, ingress object for Argo workflow dashboard and IAM is configured outside the Helm in post-deploy script.\nParameters #  The following component level parameters can be set in hub-component.yaml:\n   Name Description Default Value     component.argo.namespace Kubernetes namespace where Argo is provisioned kubeflow   component.argo.workflowNamespace Kubernetes namespace where workflow workloads are created kubeflow   component.argo.workflowRBAC Flag that enables k8s Role and RoleBinding creation in the workflowNamespace with required permissions to run workflow workloads true   component.argo.version Argo version v2.12.3   component.argo.containerRuntimeExecutor Container runtime, read more here k8sapi   component.argo.helm.chart Helm Chart version argo-workflows-0.9.4.tgz    Dependencies #  Argo Component does not depend on any other component in the stack\nReferences #   Argo Workflows Helm  "},{"id":8,"href":"/technical-documentation/components/istio-ingress-gateway/","title":"Istio Ingress Gateway","section":"Components","content":"Istio Ingress Gateway #  Current component will use a Helm chart to deploy an Istio Ingress Gateway\nParameters #     Name Description Default Value     hub.componentName Name of the istio ingress gateway    component.istio.namespace Namespace of the istio istio-system   component.istio.ingressGateway.type Reserved for future variability sds    Output parameters #     Name Description     component.istio.ingressGateway Name of istio gateeway    Implementation Specifics #  Helm chart downloaded from istio repo: https://storage.googleapis.com/istio-release/releases/$(ISTIO_VERSION)/charts/\nWe use a helm chart gateways, which is a dependency of the helm chart istio.\nValues files has been taken with with precedence to the later:\n Global values: Taken from istio/values.yaml only global; rest has been ignored Ingress gateway default values: Taken from istio/charts/gateways/values.yaml only istio-ingressgateway (renamed to hub.componentName); rest has been ignored Component values from: values.yaml.template  "},{"id":9,"href":"/technical-documentation/components/kubeflow-authn/","title":"Kubeflow Authn","section":"Components","content":"Kubeflow Authn HTTP Filter #  This is a HTTP filter for Istio (Envoy) that validates User session and redirects to dex for authentication (if invalid).\nImplementation Details #  The component has the following directory structure:\n./ ├── authn-envoy-filter.json.template # HTTP filter configuration ├── hub-component.yaml # Component definition ├── kustomization.yaml.template # Kustomize config └── oidc.yaml.template # Custom resource template for dex integration Parameters #  The following component level parameters has been defined hub-component.yaml:\n   Name Description Default Value     component.ingress.protocol HTTP or HTTPS schema https   component.dex.issuer OIDC auth URL (Dex) http://auth.${domain.name}   component.kubeflow.authn.oidcProvider Kubeflow OIDC auth URL https://kubeflow.${dns.domain}/login/oidc   component.kubeflow.authn.oidcSecret Hard to guess OIDC secret passphrase between Kubeflow and Dex (recommended: randomly generated string)    component.kubeflow.authn.sessionMaxAge Max age (in seconds) for user session 86400   component.istio.namespace Kubernetes namespace for Istio istio-system   component.istio.ingressGateway Name of Istio ingress gateway service     See Also #   Kubeflow Authn Design Article Istio documentation on Envoy Filters  "},{"id":10,"href":"/technical-documentation/components/kubeflow-central-dashboard/","title":"Kubeflow Central Dashboard","section":"Components","content":"Kubeflow Central Dashboard #  Kubeflow landing page. It provides following functionality:\n Web UI to access all Kubeflow components User registration flowA  Implementation Details #  The component has the following directory structure:\n./ ├── deployment_patch.yaml # Kustomize patch that adds extra env vars for pod ├── hub-component.yaml # Parameters definitions ├── kustomization.yaml.template # Kustomize file for ths component ├── links-config.json # Configuration for splash screen ├── params.env.template # Configuration for environment variables of a central-dashboard pod ├── params.yaml # Config for Kustomize varibles ├── pre-deploy # Script to download tarball from kubeflow distribution website ├── pre-undeploy -\u0026gt; pre-deploy ├── clusterrole-binding.yaml.template # RBAC for cluster role bindings └── role-binding.yaml.template # RBAC for role bindings The component uses an offical Kubeflow distribution Kustomize scripts as a and applies patches and additiona resources described in kustomize.yaml file.\nWhere pre-deploy script has been responsible for download tarball from Kubeflow official distribution website.\nThis component contains a special parameters to enable image pull from private docker registry\nBy default in the Kubeflow user id has been a valid email address. This is not the case for Intel, where user id is an IDSID parameter (from LDAP) which is not an email address. To allow this, we had to relax a user field validation in Add Contributor UI screen\nParameters #  The following component level parameters has been defined hub-component.yaml\n   Name Description Default Value     component.kubeflow.namespace Target Kubernetes namespace for this component kubeflow   component.kubeflow.dashboard.image Central dashboard docker image configuration gcr.io/kubeflow-images-public/centraldashboard   component.kubeflow.dashboard.imageTag Central dashboard docker image configuration vmaster-g8097cfeb   component.kubeflow.dashboard.contributorFormat REGEX to configure validation for profiles congtributor ^.+$   component.kubeflow.dashboard.contributorValidationMessage Custom error message for contributor validation ^.+$    See Also #   Kubeflow Central Dashboard official documentation Project source code on Github  "},{"id":11,"href":"/technical-documentation/components/kubeflow-jupyter-notebook/","title":"Kubeflow Jupyter Notebook","section":"Components","content":"Kubeflow Jupyter Notebook #  A web application to allow user to create, update and delete Jupyter Notebooks inside their profile. This application can work as a standalone application, however by default it wll be opened from Kubeflow Central dashboard via iframe.\nRequirements #   Requires kustomize CLI. Doesn\u0026rsquo;t work with kubectl -k ...  Implementation Details #  This component will deploy two services of the Jupyter notebbok\n jupyter-web-app - a web application notebook-controller - a BFF (backend-for-frontend) of this applicaiton.  Notebook creation form can be customized in jupyter-web-app/spawner_ui_config.yaml file.\n There was a special update to the notebook to allow user select GPUs from a dropdown.\n Once a notebook has been created. In the Kubernetes it has been represented as a Custom Resource (Notebook), so notebook controller also acts as an operator for this custom resource.\nThe component has the following directory structure:\n./ ├── crds │ └── notebook.yaml # CRD, contains previous verions, for smooth in-place upgrade ├── jupyter-web-app # Jupyter Web application (UI) │ ├── kustomization.yaml.template # Kustomize script for Jupyter web application │ ├── params.yaml # Application environment variables │ └── spawner_ui_config.yaml.template # Extracted notebook creation form config for easier customization ├── notebook-controller # Backend for UI and operator for Notebooks │ ├── kustomization.yaml.template # Kustomize script for Notebook │ └── params.env.template # Environment variables for backend ├── README.md ├── backup # Script for backups ├── deploy.sh # Customized deployment script to hook both kustomize files ├── hub-component.yaml # Hub manifest ├── post-deploy # Special addon to hook a optional restore from backup script └── undeploy.sh # Undeployment script for both kustomze applicaitons The component uses an offical Kubeflow distribution Kustomize scripts as a and applies patches and additiona resources described in kustomize.yaml file.\nWhere pre-deploy script has been responsible for download tarball from Kubeflow official distribution website.\nParameters #  The following component level parameters has been defined hub-component.yaml\n   Name Description Default Value     component.kubeflow.namespace Target Kubernetes namespace for this component kubeflow   component.kubeflow.dashboard.image Central dashboard docker image configuration gcr.io/kubeflow-images-public/centraldashboard   component.kubeflow.dashboard.imageTag Central dashboard docker image configuration vmaster-g8097cfeb   component.kubeflow.dashboard.contributorFormat REGEX to configure validation for profiles congtributor ^.+$   component.kubeflow.dashboard.contributorValidationMessage Custom error message for contributor validation ^.+$    See Also #   Central Dashboard on Kubeflow website  "},{"id":12,"href":"/technical-documentation/components/kubeflow-pipelines/","title":"Kubeflow Pipelines","section":"Components","content":"Kubeflow pipelines #  Overview of the Kubeflow pipelines service #  Kubeflow is a machine learning (ML) toolkit that is dedicated to making deployments of ML workflows on Kubernetes simple, portable, and scalable.\nKubeflow pipelines are reusable end-to-end ML workflows built using the Kubeflow Pipelines SDK.\nThe Kubeflow pipelines service has the following goals:\n End to end orchestration: enabling and simplifying the orchestration of end to end machine learning pipelines Easy experimentation: making it easy for you to try numerous ideas and techniques, and manage your various trials/experiments. Easy re-use: enabling you to re-use components and pipelines to quickly cobble together end to end solutions, without having to re-build each time.  Enables data scientists to define data pipelines (DAG) using notebook and python. We support only Multi-User isolation.\nThis component uses argo as the driver for pipelines.\nDependency #  Depends on:\n argo: (Runtime for DAG). Argo dependency is transitive (via CRD) minio: (DAG artifacts) mysql-pipelines: persistence kubeflow-profiles: (backend for multi-user isolation) kubeflow-metadata: (model outputs)  Implementation Details #  ./ ├── crds # Pipeline CRD files ├── envs # Templates for kustomize parameters ├── patches # Templates to patch existing (original) kustomize resources ├── resources # Templates to replace existing (original) kustomize resources ├── hub-component.yaml # Component definition file ├── kustomization.yaml.template # Main kustomize template file ├── pre-deploy # Downloads tarball from kubeflow distribution webiste └── pre-undeploy -\u0026gt; pre-deploy This component uses Kustomize extension and follows common design guidelines for Kustomize components.\nParameters #     Name Description Default Value     component.kubeflow.manifests.version Version of kubeflow deployment manifests v1.2.0   component.kubeflow.pipeline.multiUser Set\u0026rsquo;s for multi user isolation true   component.mysql.host MySQL server host name    component.mysql.port MySQL server port (default to 3306) 3306   component.mysql.user MySQL server username (cannot be empty)    component.mysql.password MySQL server user password (cannot be empty)    component.mysql.database MySQL server database (cannot be empty)    component.bucket.endpoint Minio endpoint expected internal endpoint (cluster.local)    component.bucket.host Hostname part of of the endpoint    component.bucket.port Minio service port    component.bucket.region Minio region    component.bucket.accessKey Minio access key id    component.bucket.secretKey Minio secret access key     Changelog and TODOs #  Since Kubeflow v1.2 #   Introduced since kubeflow v1.2   NOTE: this component has been subject of heavy changes since Kubeflow v1.3 upgrade might not be backward compatible (on infrastructure as code level)\n See Also #   Getting Started Multi User Isolation  "},{"id":13,"href":"/technical-documentation/requirements/gke/access-rights/","title":"Access Rights","section":"GKE","content":"Access rights #  Comming soon #  "},{"id":14,"href":"/technical-documentation/requirements/gke/addons/","title":"Addons","section":"GKE","content":"GKE Addons #  Comming soon #  "},{"id":15,"href":"/technical-documentation/requirements/gke/sufficient-capacity/","title":"Sufficient Capacity","section":"GKE","content":"Sufficient capacity #  Comming soon #  "},{"id":16,"href":"/user-guides/how-can-i-run-pipeline-from-my-machine/","title":"How Can I Run Pipeline From My Machine","section":"User-guides","content":"How can I run pipeline from my machine #  Comming soon #  "},{"id":17,"href":"/getting-started/faq/","title":"FAQ","section":"Getting Started","content":"FAQ #  Comming soon #  "},{"id":18,"href":"/getting-started/deploy-kubeflow-on-cloud/deploy-on-gke/","title":"Kubeflow on GKE","section":"Deploy Kubeflow on Cloud","content":"Kubeflow on GKE #  Here we explain how to deploy a Kubeflow into your Google Cloud Platform environment\nDeployment Prerequisites #   You should be signed in and have an active project in GCP: https://console.cloud.google.com You should have already deployed a GKE cluster.   Don\u0026rsquo;t have a cluster? Not a problem. We have a GKE stack for you, follow this link\n Deployment #  Deployment via Cloud Shell #  The easiest way how to get started is via Cloud Shell Edititor. Choose from the list of available Kubeflow stacks\n   Kubeflow Stack Description Link     Kubeflow cluster v1.2 This is our latest Kubeflow stack available     Start a new cloud shell session #  What will happen when you click to the button:\n You will start a new Cloud Shell editor session (best works with the Chrome Browser) Cloud shell will use a Shellbox image with all tools needed to deploy a kubeflow. No additional configuration required, See shellbox on gcr Cloud shell will clone a git repo with the stack files: See github repo: kubeflow-stacks  Init stack #  First you need initialize the sandbox configuration. To do this please run the initialization command:\nhub stack init The command will:\n Download the components described in hub.yaml Configure this Cloud Shell session for your GCP. It will ask other GCP essentials. It will take Region and Location (zone) from GCP metadat aserver. You can change settings by modifying .env file  Configure and Deploy a stack #  Once you are done with the configuration, use the following command to deploy the sandbox:\nhub stack deploy Before the first deployment you will be prompted for few questions. Your settings will be captured in .env file.\n Name of GKE cluster in your region. You will see a list of already deployed GKE clusters in your region. For different region, please adjust variables in .env file and thern run hub stack deploy command again Name of the storage class (more info here) GKE provides several storage classes you will see them Other questions\u0026hellip;  Once all configuration settings completed it will start the deployment automatically\nReview configuration parameters before deployment #  Wait, not so fast! I want to review coniguration settings (and possibly adjust) before the deployment.\nIn this case, run the following command\nhub stack configure This command will only do a configuration step and save results in .env file. So you can review and adjust. Once you are happy then run\nhub stack deploy Clean Up #  To remove your Kubeflow deployment, please run the following command\nhub stack undeploy "},{"id":19,"href":"/getting-started/examples/mnist-example/","title":"MNIST example","section":"Examples","content":"MNIST example #  Comming soon #  "}]