[{"id":0,"href":"/components/pipelines/","title":"Pipelines","section":"Components","content":"Kubeflow pipelines #  Overview of the Kubeflow pipelines service #  Kubeflow is a machine learning (ML) toolkit that is dedicated to making deployments of ML workflows on Kubernetes simple, portable, and scalable.\nKubeflow pipelines are reusable end-to-end ML workflows built using the Kubeflow Pipelines SDK.\nThe Kubeflow pipelines service has the following goals:\n End to end orchestration: enabling and simplifying the orchestration of end to end machine learning pipelines Easy experimentation: making it easy for you to try numerous ideas and techniques, and manage your various trials/experiments. Easy re-use: enabling you to re-use components and pipelines to quickly cobble together end to end solutions, without having to re-build each time.  "},{"id":1,"href":"/stacks/kubeflow-gcp/","title":"Kubeflow Gcp","section":"Kubeflow","content":"Kubeflow Stack on GCP #  Here we explain how to deploy a Kubeflow into your Google Cloud Platform environment\nDeployment Prerequisites #   You should be signed in and have an active project in GCP: https://console.cloud.google.com You should have already deployed a GKE cluster.   Don\u0026rsquo;t have a cluster? Not a problem. We have a GKE stack for you, follow this link\n Deployment #  Deployment via Cloud Shell #  The easiest way how to get started is via Cloud Shell Edititor. Choose from the list of available Kubeflow stacks\n   Kubeflow Stack Description Link     Kubeflow cluster v1.2 This is our latest Kubeflow stack available     Start a new cloud shell session #  What will happen when you click to the button:\n You will start a new Cloud Shell editor session (best works with the Chrome Browser) Cloud shell will use a Shellbox image with all tools needed to deploy a kubeflow. No additional configuration required, See shellbox on gcr Cloud shell will clone a git repo with the stack files: See github repo: kubeflow-stacks  Init stack #  First you need initialize the sandbox configuration. To do this please run the initialization command:\nhub stack init The command will:\n Download the components described in hub.yaml Configure this Cloud Shell session for your GCP. It will ask other GCP essentials. It will take Region and Location (zone) from GCP metadat aserver. You can change settings by modifying .env file  Configure and Deploy a stack #  Once you are done with the configuration, use the following command to deploy the sandbox:\nhub stack deploy Before the first deployment you will be prompted for few questions. Your settings will be captured in .env file.\n Name of GKE cluster in your region. You will see a list of already deployed GKE clusters in your region. For different region, please adjust variables in .env file and thern run hub stack deploy command again Name of the storage class (more info here) GKE provides several storage classes you will see them Other questions\u0026hellip;  Once all configuration settings completed it will start the deployment automatically\nReview configuration parameters before deployment #  Wait, not so fast! I want to review coniguration settings (and possibly adjust) before the deployment.\nIn this case, run the following command\nhub stack configure This command will only do a configuration step and save results in .env file. So you can review and adjust. Once you are happy then run\nhub stack deploy Clean Up #  To remove your Kubeflow deployment, please run the following command\nhub stack undeploy "},{"id":2,"href":"/components/","title":"Components","section":"","content":"List of components #   Pipelines  "},{"id":3,"href":"/stacks/","title":"Kubeflow","section":"","content":"Available Kubeflow Stacks #  TBD\n"}]